'use client'

import type { StoryAssets } from '@/lib/ai/tools/animation-assets/generate-animation-assets-v2'
import { getMediaUrl } from '@/lib/media-proxy'
import { client } from '@/lib/rpc/orpc.client'
import * as core from '@diffusionstudio/core'
import { use$, useMount } from '@legendapp/state/react'
import { useEffect, useRef } from 'react'
import { useHover, useResizeObserver } from 'usehooks-ts'

import { PlaybackControls } from './playback-controls'
import { useVideoComposer } from './video-composer-provider'

// æ–°çš„åˆæˆæ•°æ®ç»“æ„
type CompositionShot = {
  shotId: string
  sceneId: string
  title: string
  audioUrl: string
  audioDuration?: number // ç§’
  whiteboardVideoUrl?: string // ç™½æ¿åŠ¨ç”»è§†é¢‘URLï¼ˆå¯é€‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™åªæœ‰éŸ³é¢‘ï¼‰
}

type VideoPlayerProps = {
  storyAssets?: StoryAssets
  storyId?: string // æ–°å¢ï¼šç”¨äºæŸ¥è¯¢å®é™…çš„èµ„äº§æ•°æ®
}

export function VideoPlayer({ storyAssets, storyId }: VideoPlayerProps) {
  const { state$, composition, attachPlayer, updatePlayerScale } =
    useVideoComposer()
  const containerRef = useRef<HTMLDivElement>(null)
  const playerRef = useRef<HTMLDivElement>(null)
  const isHovered = useHover(containerRef)

  const playerScale = use$(state$.playerScale)
  const isLoading = use$(state$.isLoading)

  useEffect(() => {
    if (playerRef.current) {
      attachPlayer(playerRef.current)
    }
  }, [])

  useSetupComposition(composition, storyAssets, storyId)

  useResizeObserver({
    ref: containerRef,
    onResize: ({ width, height }) => {
      if (composition && width && height) {
        updatePlayerScale(width, height)
      }
    },
  })

  if (isLoading) {
    return (
      <div
        className="relative mx-auto flex aspect-video w-full items-center justify-center overflow-hidden bg-black/30"
        ref={containerRef}
      >
        <div className="text-muted-foreground text-xl">
          Loading composition...
        </div>

        {/* Floating Controls */}
        <div
          className={`bg-background absolute right-0 bottom-0 left-0 p-3 transition-opacity duration-300 ${
            isHovered ? 'opacity-100' : 'opacity-0'
          }`}
        >
          <PlaybackControls />
        </div>
      </div>
    )
  }

  return (
    <div
      className="relative mx-auto flex aspect-video w-full items-center justify-center overflow-hidden bg-black/30"
      ref={containerRef}
    >
      <div
        ref={playerRef}
        style={{
          width: composition ? `${composition.width}px` : '1920px',
          height: composition ? `${composition.height}px` : '1080px',
          transform: `scale(${playerScale})`,
          transformOrigin: 'center',
        }}
      />

      {/* Floating Controls */}
      <div
        className={`bg-background absolute right-0 bottom-0 left-0 p-3 transition-opacity duration-300 ${
          isHovered ? 'opacity-100' : 'opacity-0'
        }`}
      >
        <PlaybackControls />
      </div>
    </div>
  )
}

function useSetupComposition(
  composition: core.Composition,
  _storyAssets?: StoryAssets, // ä¿ç•™å‚æ•°ä½†æ ‡è®°ä¸ºæœªä½¿ç”¨
  storyId?: string,
) {
  const isInit = useRef(false)

  useMount(async function init() {
    if (isInit.current) return
    isInit.current = true

    console.log(
      'ğŸ¬ [VideoComposer] Setting up composition with story ID:',
      storyId,
    )

    if (!storyId) {
      console.warn('ğŸ¬ [VideoComposer] No story ID provided, using test assets')
      await setupDemoComposition(composition)
      return
    }

    // æŸ¥è¯¢å¹¶ç»„è£…çœŸå®çš„åˆæˆæ•°æ®
    const compositionShots = await fetchCompositionData(storyId)
    if (compositionShots.length === 0) {
      console.warn(
        'ğŸ¬ [VideoComposer] No composition data found, using test assets',
      )
      await setupDemoComposition(composition)
      return
    }

    await setupRealComposition(composition, compositionShots)
  })
}

async function setupDemoComposition(composition: core.Composition) {
  console.log('ğŸ¬ [VideoComposer] Setting up demo composition')

  // Add video clip using new v3 API
  const videoSource = await core.Source.from<core.VideoSource>(
    '/sample_aac_h264_yuv420p_1080p_60fps.mp4',
  )
  const video = new core.VideoClip(videoSource, {
    volume: 0.1,
    position: 'center',
    height: '100%',
  })
  video.subclip(30, 540).offset(30)
  await composition.add(video)

  // Add image using new v3 API
  const image = new core.ImageClip('/lenna.png', {
    position: 'center',
    height: 600,
    delay: 0,
    duration: 300,
  })
  await composition.add(image)

  // Add audio clip using new v3 API
  const audioSource = await core.Source.from<core.AudioSource>('/harvard.MP3')
  const audioClip = new core.AudioClip(audioSource)
  await composition.add(audioClip)

  // Add text clips using new v3 API
  const textClip = new core.TextClip({
    text: 'Basic text in Diffusion Studio',
    duration: 120,
    align: 'center',
    baseline: 'middle',
    x: composition.width / 2,
    y: composition.height * 0.15,
    color: '#ffffff',
    stroke: {
      width: 3,
      color: '#000000',
    },
  })
  await composition.add(textClip)
}

// ä»æ•°æ®åº“æŸ¥è¯¢å¹¶ç»„è£…åˆæˆæ•°æ®
async function fetchCompositionData(
  storyId: string,
): Promise<CompositionShot[]> {
  try {
    console.log(
      'ğŸ¬ [VideoComposer] Fetching composition data for story:',
      storyId,
    )

    // ä½¿ç”¨ client å®ä¾‹ç›´æ¥è°ƒç”¨åç«¯API
    const data = await client.getAnimationAsset({ storyId })
    console.log('ğŸ¬ [VideoComposer] Raw asset data:', data)

    // ç»„è£…åˆæˆé•œå¤´æ•°æ®ï¼ˆæŒ‰ scenes -> shots çš„æœ‰åºç»“æ„ï¼‰
    const shots: CompositionShot[] = []
    const assetsByScene = data.assetsByScene || {}

    // æŒ‰åœºæ™¯IDæ’åºï¼ˆç°åœ¨ sceneId æ˜¯å­—ç¬¦ä¸²ï¼Œä½†ä»ç„¶å¯ä»¥æŒ‰æ•°å­—æ’åºï¼‰
    const sceneIds = Object.keys(assetsByScene).sort(
      (a, b) => parseInt(a) - parseInt(b),
    )

    for (const sceneId of sceneIds) {
      const sceneAssets = assetsByScene[sceneId]

      // æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘
      if (!sceneAssets.audio || sceneAssets.audio.status !== 'completed') {
        console.warn(
          `ğŸ¬ [VideoComposer] Scene ${sceneId} missing completed audio, skipping`,
        )
        continue
      }

      // æŸ¥æ‰¾ç™½æ¿åŠ¨ç”»
      const whiteboardAsset = sceneAssets.whiteboardAnimation

      // æ£€æŸ¥ç™½æ¿åŠ¨ç”»æ˜¯å¦å®Œæˆï¼ˆå¦‚æœæ²¡æœ‰ç™½æ¿åŠ¨ç”»ï¼Œä»ç„¶å¯ä»¥æ·»åŠ éŸ³é¢‘ï¼‰
      if (!whiteboardAsset || whiteboardAsset.status !== 'completed') {
        console.warn(
          `ğŸ¬ [VideoComposer] Scene ${sceneId} whiteboard animation not ready, will only add audio`,
        )
      }

      // åˆ›å»ºé•œå¤´æ•°æ®ï¼ˆæ¯ä¸ªåœºæ™¯å¯¹åº”ä¸€ä¸ªé•œå¤´ï¼‰
      const shot: CompositionShot = {
        shotId: `${sceneId}-1`, // åœºæ™¯ID + é•œå¤´ç¼–å·ï¼ˆä¿æŒå­—ç¬¦ä¸²æ ¼å¼ï¼‰
        sceneId: sceneId, // ç¡®ä¿ sceneId æ˜¯å­—ç¬¦ä¸²
        title: `Scene ${sceneId}`, // å¯ä»¥ä»storyæ•°æ®ä¸­è·å–çœŸå®æ ‡é¢˜
        audioUrl: sceneAssets.audio.s3Url,
        audioDuration: sceneAssets.audio.duration
          ? parseFloat(sceneAssets.audio.duration)
          : undefined,
        whiteboardVideoUrl:
          whiteboardAsset?.status === 'completed'
            ? whiteboardAsset.s3Url
            : undefined,
      }

      shots.push(shot)
      console.log(`ğŸ¬ [VideoComposer] Added shot ${shot.shotId}:`, {
        shotId: shot.shotId,
        audioUrl: shot.audioUrl,
        audioDuration: shot.audioDuration,
        whiteboardVideoUrl: shot.whiteboardVideoUrl,
        audioProxyUrl: shot.audioUrl ? getMediaUrl(shot.audioUrl) : 'N/A',
        videoProxyUrl: shot.whiteboardVideoUrl
          ? getMediaUrl(shot.whiteboardVideoUrl)
          : 'N/A',
      })
    }

    console.log(
      `ğŸ¬ [VideoComposer] Assembled ${shots.length} shots for composition`,
    )
    return shots
  } catch (error) {
    console.error('ğŸ¬ [VideoComposer] Error fetching composition data:', error)
    return []
  }
}

// ä½¿ç”¨çœŸå®æ•°æ®è®¾ç½®åˆæˆ
async function setupRealComposition(
  composition: core.Composition,
  shots: CompositionShot[],
) {
  console.log(
    'ğŸ¬ [VideoComposer] Setting up real composition with',
    shots.length,
    'shots',
  )

  // åˆ›å»º sequential layers æ¥ç¡®ä¿éŸ³é¢‘å’Œè§†é¢‘æŒ‰é¡ºåºæ’­æ”¾
  const audioLayer = composition.createLayer().sequential()
  const videoLayer = composition.createLayer().sequential()

  console.log(
    'ğŸ¬ [VideoComposer] Created sequential layers for audio and video',
  )

  for (let i = 0; i < shots.length; i++) {
    const shot = shots[i]
    console.log(
      `ğŸ¬ [VideoComposer] Processing shot ${shot.shotId}: "${shot.title}"`,
    )

    try {
      // å…ˆéªŒè¯ S3 æ–‡ä»¶æ˜¯å¦å¯è®¿é—®
      console.log(`ğŸ” [VideoComposer] Verifying audio URL:`, shot.audioUrl)
      try {
        const audioResponse = await fetch(shot.audioUrl, { method: 'HEAD' })
        console.log(`ğŸµ [VideoComposer] Audio URL status:`, {
          status: audioResponse.status,
          contentType: audioResponse.headers.get('content-type'),
          contentLength: audioResponse.headers.get('content-length'),
          url: shot.audioUrl,
        })
      } catch (fetchError) {
        console.error(
          `âŒ [VideoComposer] Cannot access audio URL:`,
          shot.audioUrl,
          fetchError,
        )
      }

      // æ·»åŠ éŸ³é¢‘åˆ° sequential audio layer
      const audioProxyUrl = getMediaUrl(shot.audioUrl)
      console.log(
        `ğŸµ [VideoComposer] Adding audio:`,
        shot.audioUrl,
        '-> proxy:',
        audioProxyUrl,
      )
      const audioClip = new core.AudioClip(audioProxyUrl)
      await audioLayer.add(audioClip)

      // æ·»åŠ ç™½æ¿åŠ¨ç”»è§†é¢‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
      if (shot.whiteboardVideoUrl) {
        const videoProxyUrl = getMediaUrl(shot.whiteboardVideoUrl)
        console.log(
          `ğŸ¬ [VideoComposer] Adding whiteboard animation (muted):`,
          shot.whiteboardVideoUrl,
          '-> proxy:',
          videoProxyUrl,
        )
        const videoClip = new core.VideoClip(videoProxyUrl, {
          position: 'center',
          height: '100%',
          volume: 0, // ç¡®ä¿ç™½æ¿åŠ¨ç”»è§†é¢‘æ— å£°
        })
        await videoLayer.add(videoClip)
      } else {
        console.warn(
          `ğŸ¬ [VideoComposer] Shot ${shot.shotId} has no whiteboard animation`,
        )
      }

      console.log(`âœ… [VideoComposer] Shot ${shot.shotId} added successfully`)
    } catch (error) {
      console.error(
        `ğŸ¬ [VideoComposer] Error processing shot ${shot.shotId}:`,
        error,
      )
    }
  }

  // è®¡ç®—å¹¶è®¾ç½®åˆæˆçš„æ€»æ—¶é•¿
  try {
    const totalDurationSeconds = audioLayer.clips.reduce((acc, clip) => {
      return acc + clip.duration.seconds
    }, 0)
    const totalDuration = new core.Timestamp(0, totalDurationSeconds)

    if (!(totalDurationSeconds > 0)) {
      console.error(
        'ğŸ¬ [VideoComposer] Total duration is 0, setting to 30 seconds',
      )
      throw new Error('Total duration is 0')
    }

    console.log(
      `ğŸ¬ [VideoComposer] Setting composition duration to ${totalDuration.seconds} seconds`,
    )

    composition.duration = new core.Timestamp(0, 30)
  } catch (error) {
    console.error(
      'ğŸ¬ [VideoComposer] Error setting composition duration:',
      error,
    )
  }

  console.log(
    'ğŸ¬ [VideoComposer] Real composition setup complete using sequential layers',
  )
}
